%!TEX root = main.tex

\subsection*{Proof of Theorem \ref{lem-support}}

{\bf For }$\boldsymbol{\fqfo(\fo).}$ Let $\R$ be a signature. We prove the statement for $\fqfo(\fo)$ over $\R$.

We prove inductively that for each formula $\beta(\bar{x},h)$ in $\fqfo(\fo)$ over $\R$, for a given pair of functions $f,g$ such that $\supp(f)\subseteq\supp(g)$, it holds that $\supp(T_{\beta}(f))\subseteq\supp(T_{\beta}(g))$. Let $\length{\bar{x}} = \ell$.

We separate the proof in each case determined by the $\fqfo$ grammar. For each of the following cases.
\begin{itemize}
\item[1.] $\beta$ is either equal to a constant $s$ or an $\fo$ formula $\varphi$. Then $h$ does not appear. Then, for each structure $\A$, each first-order assignment $v$ and functional assignments $F,G$ over $\A$, we have that $\sem{\beta(\bar{x},h)}(\A,v,F) = \sem{\beta(\bar{x},h)}(\A,v,G)$. As a result, $\supp(T_{\beta}(f)) = \supp(T_{\beta}(g))$ for every pair of functions $f,g$.
\item[2.] $\beta$ is equal to $h(\bar{y})$ for some subtuple $\bar{y}$ of $\bar{x}$. Then $T_{\beta}(f) = f$ and $T_{\beta}(g) = g$ and the condition holds trivially.
\end{itemize}
Suppose that the statement holds for each formula smaller than $\beta$.
\begin{itemize}
\item[3.] $\beta = (\beta_1 + \beta_2)$. It is easy to see that for each $\bar{a} \in A^{\ell}$ and function $f:A^{\ell}\to\nat$: $T_{\beta}(f)(\bar{a}) = T_{\beta_1}(f)(\bar{a}) + T_{\beta_2}(f)(\bar{a})$. Suppose $\supp(f)\subseteq\supp(g)$ and let $\bar{a} \in \supp(T_{\beta}(f))$, or in other words, $T_{\beta}(f)(\bar{a}) > 0$. Then, for some $\beta_i$ it holds that $T_{\beta_i}(f)(\bar{a}) > 0$. From the supposition we have that $T_{\beta_i}(g)(\bar{a}) > 0$ from which the statement follows.
\item[4.] $\beta = (\beta_1 \mult \beta_2)$. It is easy to see that for each $\bar{a}$ in $A^{\ell}$ and function $f:A^{\ell}\to\nat$: $T_{\beta}(f)(\bar{a}) = T_{\beta_1}(f)(\bar{a}) \mult T_{\beta_2}(f)(\bar{a})$. Suppose $\supp(f)\subseteq\supp(g)$ and let $\bar{a}$ be such that $T_{\beta}(f)(\bar{a}) > 0$. Then $T_{\beta_i}(f)(\bar{a}) > 0$ for both $\beta_i$. From the supposition we have that $T_{\beta_i}(g)(\bar{a}) > 0$ for both $\beta_i$ and the statement holds.
\item[5.] $\beta = \sa{y}\delta(y,\bar{x},h)$. Here we extend the grammar slightly to allow constants, and we use the notation $\delta[a/y]$ to denote the formula obtained by replacing each instance of $y$ by the constant $a$. It can be seen that $T_{\beta}(f)(\bar{a}) = \sum_{a \in A} T_{\delta[a/y]}(f)(\bar{a})$. Suppose $\supp(f)\subseteq\supp(g)$ and let $\bar{a}$ be such that $T_{\beta}(f)(\bar{a}) > 0$. Then for some $a\in A$ we have $T_{\delta[y/a]}(f)(\bar{a}) > 0$. The statement now follows as in the case 3.
\item[6.] $\beta = \pa{y}\delta(y,\bar{x},h)$. 
It can be seen that $T_{\beta}(f)(\bar{a}) = \prod_{a \in A} T_{\delta[a/y]}(f)(\bar{a})$. 
%If $T_{\beta}(f)(\bar{a}) > 0$, then $T_{\delta[y/a]}(f)(\bar{a}) > 0$ for each $a\in A$. As in the $\mult$ case, the statement follows directly.
The statement follows using the same argument from cases 4 and 5.
\end{itemize}
This covers all possible cases for $\beta$ and we finish the proof of the statement for $\fqfo(\fo)$.

\vspace{1em}
{\bf For} $\boldsymbol{\rqfo(\fo).}$ The only additional case is where $\beta = \clfp{\delta(\bar{y},h')}$ for some subtuple $\bar{y}$ of $\bar{x}$. We have that $\beta$ does not mention $h$, and so, the statement follows directly as we showed in the previous part of the proof.


\subsection*{Proof of Theorem \ref{rqfo-fo-cap}}

Given the definition of the semantics of $\rqfo(\fo)$, it is clear that a fixed formula $\clfp{\beta(\x, h)}$ can be evaluated in polynomial time, from which it is possible to conclude that each fixed formula in $\rqfo(\fo)$ can be evaluated in polynomial time. Thus, to prove that $\rqfo(\fo)$ captures $\fp$, we only need to prove the second condition in Definition \ref{def:cap}.
%
%Let $\R$ be a relational signature. First we prove the first condition in Definition \ref{def:cap}. Let $\alpha$ be a formula in $\tqfo(\fo)$.
%We will recursively construct a deterministic polynomial-space algorithm $M_{\alpha}$ that on input $(\enc(\A),\enc(v),\enc(F))$, where $v$ is a first-order assignment and $F$ is a function assignment, outputs the value $\sem{\alpha}(\A,v)$.
%From this point on we use $\A$, $v$ and $F$ to denote $\enc(\A)$, $\enc(v)$ and $\enc(F)$ respectively.
%Suppose the domain of $\A$ is $A = \{1,\ldots,n\}$.
%If $\alpha = \varphi$, a formula in $\fo$, we check if $(\A,v,F)\models\varphi$ in deterministic polynomial-space space, and output 1.
%If $\alpha = s$, we write $s$ as output.
%If $\alpha = (\alpha_1 + \alpha_2)$, we compute $M_{\alpha_1}$ and $M_{\alpha_2}$ on input $(\A,v,F)$ and give the sum of the values as output.
%If $\alpha = (\alpha_1\cdot\alpha_2)$, we compute $M_{\alpha_1}$ and $M_{\alpha_2}$ on input $(\A,v,F)$ and give the product of the values as output.
%If $\alpha = \sa{x}\beta$, we iterate for each $a\in A$, compute $M_{\beta}$ on input $(\A,v[a/x],F)$, and give the sum of all values as output.
%If $\alpha = \pa{x}\beta$, we iterate for each $a\in A$, compute $M_{\beta}$ on input $(\A,v[a/x],F)$, and give the product of all values as output.
%If $\alpha = \clfp{\beta(\bar{x},h)}$, we compute each of the functions $f_0,\ldots,f_k$ iteratively. We start from the null function $f_0$ and compute $f_i$ on each step. If at any point $\supp(f_i) = \supp(f_{i+1})$, then we stop iterating and output $f_i(v(\bar{x}))$.
%This ends the construction of the algorithm.
%Consider $f$ as the $\fp$ function associated to this procedure and we have that for each finite $\R$-structure $\A$: $f(\enc(\A)) = \sem{\alpha}(\A)$.
%
%\vspace{1em}
%
%
%Now we prove the second condition in Definition \ref{def:cap}.
%Let $f\in\fp$ be defined over $\R$. Recall that in the proof for Theorem \ref{theo:capture-fp} we constructed a formula $\alpha = \sa{\bar{x}}\Phi(\bar{x})\mult\varphi(\bar{x})$ in $\qfo(\lfp)$ where $\Phi(\bar{x})$ is a formula in $\lfp$ extended with constants over the signature $\R \cup \{\bar{x}\}$. We use the construction used by Gradel in \cite{G07} to capture $\ptime$ with $\lfp$. Consider the function defined by the operator $\clfp{\varphi(\bar{x},h)}(\bar{x})$. This corresponds exactly to the function:
%$$
%f(\A,v(\bar{x})) 
%\begin{cases}
%1 &(\A,v)\models [{\bf lfp}\,{\varphi(\bar{x},R)}](\bar{x}), \\
%0 &\text{ in other case.}
%\end{cases}
%$$
%Then, each formula $[{\bf lfp}\,{\varphi(\bar{x},R)}]$ in $\Phi$ can be replaced by $\clfp{\varphi(\bar{x},h)}$ to obtain an equivalent formula $\alpha'$. We have that $\alpha'$ is in $\rqfo(\fo)$ and for each $\A\in\ostr[\R]$ it holds that $\sem{\alpha'}(\A) = f(\enc(\A))$.

\newcommand{\ttB}{\mathtt{B}}
\newcommand{\successor}{\text{succ}}

%For the second condition, 
Let $f$ be a function in $\fp$. We address the case when $f$ is defined for the encodings of the structures of a relational signature $\R = \{ E(\cdot, \cdot) \}$, as the proof for an arbitrary signature is analogous.
%$\R$ contains only one binary predicate $E$, and the remaining cases can be deduced from this. 
 Let $M$ be a deterministic polynomial-time TM with a working tape and an output tape, such that the output of $M$ on input $\enc(\A)$ is $f(\enc(\A))$ for each $\R$-structure $\A$. We assume that $M = (Q,\{0,1\},q_0,\delta)$, 
 %without final states, 
 where $Q = \{q_0,\ldots,q_{\ell}\}$, and $\delta:Q\times\{0,1,\ttB, \vdash\}\to Q\times\{0,1,\ttB, \vdash\}\times \{\leftarrow,\rightarrow\}\times\{0,1,\emptyset\}$ is a partial function. In particular, the tapes of $M$ are infinite to the right so the symbol $\vdash$ is used to indicate the first position in each tape, and $M$ does not have any final states, as it produces an output for each input. Moreover, the only allowed operations in the output tape are: 
 %The machine has an output tape and the only allowed operations in that tape on each step are 
 (1) writing 0 and moving the head one cell to the right, (2) writing 1 and moving the head one cell to the right, or (3) doing nothing. These operations are represented by the set $\{0,1,\emptyset\}$. Finally, assume that $M$, on input $\enc(\A)$ with domain $A = \{1,\dots,n\}$, executes exactly $n^k$ steps for some $k \geq 1$.

We construct a formula $\alpha$ in an extension of the grammar of $\rqfo(\fo)$ such that $\sem{\alpha}(\A) = f(\enc(\A))$ for each $\R$-structure $\A$. This extension allows defining the operator ${\bf lsfp}$ for multiple functions, analogously to the notion of simultaneous LFP~\cite{L04}.
%generalization of fixed-point operator with multiple predicates. 
Let $\bar{x} = (x_1,\ldots,x_k)$ and $\bar{t} = (t_1,\ldots,t_k)$. Then $\alpha$ is defined as:
\begin{align*}
\alpha = \sa{\bar{t}}\clfp{out(\bar{t}): \,&\alpha_{T_0}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{T_1}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{T_{\ttB}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{T_{\vdash}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{h}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{\hat{h}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{s_{q_0}}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\vdots \\
	&\alpha_{s_{q_{\ell}}}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out),\\
	&\alpha_{out}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out)}\mult \last(\bar{t}).
\end{align*}
Function $T_0$ is used to indicate whether the content of a cell of the working tape is 0 at some point of time, that is, $T_0(\bar{t},\bar{x}) > 0$ if the cell at position $\bar{x}$ of the working tape contains the symbol 0 at step $\bar{t}$, and $T_0(\bar{t},\bar{x}) = 0$ otherwise. Functions $T_1$, $T_{\ttB}$ and $T_{\vdash}$ are defined analogously. Function $h$ is used to indicate whether the head of the working tape is in some position at some point of time, that is, $h(\bar{t},\bar{x}) > 0$ if the head of the working tape is at position $\bar{x}$ at step $\bar{t}$, and $h(\bar{t},\bar{x}) = 0$ otherwise. 
Function $\hat{h}$ is used to indicate whether the head of the working tape is {\bf not} in some position at some point of time, that is, $\hat{h}(\bar{t},\bar{x}) > 0$ if the head of the working tape is {\bf not} at position $\bar{x}$ at step $\bar{t}$, and $h(\bar{t},\bar{x}) = 0$ otherwise. For each $i \in \{0, \ldots, \ell\}$, function 
$s_{q_i}$ is used to indicate whether the TM $M$ is in state $q_i$ at some point of time, that is, $s_{q_i}(\bar{t}) > 0$ if the TM $M$ is in state $q_i$ at step $\bar{t}$, and $s_{q_i}(\bar{t},\bar{x}) = 0$ otherwise. Finally, function $out$ stores the output of the TM $M$; in particular, $out(\bar t)$ is the value returned by $M$ when $\bar t$ is the last step (that is, when $\last(\bar t)$ holds).

Formulas $\alpha_{T_0}$, $\alpha_{T_1}$, $\alpha_{T_{\ttB}}$ and $\alpha_{T_{\vdash}}$ are defined as follows, assuming that $\bar y = (y_1, \ldots, y_k)$:
\begin{align*}
\alpha_{T_0}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \,&(\first(\bar{t}) \wedge \exists\bar{y}(\first(y_1,\ldots,y_{k-2})\wedge\neg E(y_{k-1},y_k) \wedge \successor(\bar{y},\bar{x}) ))+ \\
&\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult \hat{h}(\bar{t}',\bar{x}) \mult T_0(\bar{t}',\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',0,op,v)}\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}) \mult T_a(\bar{t}',\bar{x}) \mult s_{q}(\bar{t}')),\\
\alpha_{T_1}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \,&(\first(\bar{t}) \wedge \exists\bar{y}(\first(y_1,\ldots,y_{k-2})\wedge E(y_{k-1},y_k) \wedge \successor(\bar{y},\bar{x}) ))+ \\
&\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult \hat{h}(\bar{t}',\bar{x}) \mult T_1(\bar{t}',\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',1,op,v)}\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}) \mult T_a(\bar{t}',\bar{x}) \mult s_{q}(\bar{t}')),\\
\alpha_{T_{\ttB}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \,&(\first(\bar{t})\wedge\exists\bar{y}\exists\bar{y}'(\first(y_1,\ldots,y_{k-2})\wedge\last(y_{k-1},y_k)\wedge\successor(\bar{y},\bar{y}')\wedge\bar{y}' < \bar{x})) + \\
&\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult \hat{h}(\bar{t}',\bar{x}) \mult T_{\ttB}(\bar{t}',\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',{\ttB},op,v)}\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}) \mult T_a(\bar{t}',\bar{x}) \mult s_{q}(\bar{t}')),\\
\alpha_{T_{\vdash}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \,&(\first(\bar{t}) \wedge \first(\bar{x})) + \\
&\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult \hat{h}(\bar{t}',\bar{x}) \mult T_{\vdash}(\bar{t}',\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',\vdash,op,v)}\sa{\bar{t}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}) \mult T_a(\bar{t}',\bar{x}) \mult s_{q}(\bar{t}')).
\end{align*}
Formulas $\alpha_{h}$ and $\alpha_{\hat{h}}$ are defined as:
\begin{align*}
\alpha_{h}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},&h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \\
& (\first(\bar{t}) \wedge \successor(\bar{t},\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',b,\leftarrow,v)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult \successor(\bar{x},\bar{x}')\mult T_a(\bar{t}',\bar{x}') \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}')) + \\
&\bigplus_{\delta(q,a) = (q',b,\rightarrow,v)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult \successor(\bar{x}',\bar{x})\mult T_a(\bar{t}',\bar{x}') \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}')),\\
\alpha_{\hat{h}}(\bar{t},\bar{x},T_0,T_1,T_{\ttB},T_{\vdash},&h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \\
& (\first(\bar{t}) \wedge \neg\successor(\bar{t},\bar{x})) + \\
&\bigplus_{\delta(q,a) = (q',b,\leftarrow,v)}\sa{\bar{t}'}\sa{\bar{x}'}\sa{\bar{x}''}(\successor(\bar{t}',\bar{t}) \mult T_a(\bar{t}',\bar{x}')  \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}') \mult \successor(\bar{x}'',\bar{x}') \mult (\bar{x} \neq \bar{x}'')) + \\
&\bigplus_{\delta(q,a) = (q',b,\rightarrow,v)}\sa{\bar{t}'}\sa{\bar{x}'}\sa{\bar{x}''}(\successor(\bar{t}',\bar{t}) \mult T_a(\bar{t}',\bar{x}')  \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}') \mult \successor(\bar{x}',\bar{x}'') \mult (\bar{x} \neq \bar{x}'')).
\end{align*}
Formula $\alpha_{q_0}$ is defined as:
%we define a formula that models which state the machine is in at each time,
\begin{align*}
\alpha_{q_0}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = \,& \first(\bar{t}) + \\
&\bigplus_{\delta(q,a) = (q_0,b,op,v)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult T_a(\bar{t}',\bar{x}') \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}')).
\end{align*}
Moreover, for every $i \in \{1, \ldots, \ell\}$, formula $\alpha_{q_i}$ is defined as:
\begin{align*}
\alpha_{q_i}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) = &\bigplus_{\delta(q,a) = (q_i,b,op,v)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult T_a(\bar{t}',\bar{x}') \mult h(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}')).
\end{align*}
Finally, formula $\alpha_{out}$ is defined as:
%And lastly we define a function that computes the output at each time.
\begin{align*}
\alpha_{out}(\bar{t},T_0,T_1,T_{\ttB},T_{\vdash},&h,\hat{h},s_{q_0},\ldots,s_{q_{\ell}},out) =\\
&\bigplus_{\delta(q,a) = (q',b,op,0)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}') \mult T_a(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}') \mult 2\mult out(\bar{t}')) + \\
&\bigplus_{\delta(q,a) = (q',b,op,1)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}') \mult T_a(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}') \mult (2\mult out(\bar{t}')+1)) + \\ 
&\bigplus_{\delta(q,a) = (q',b,op,\emptyset)}\sa{\bar{t}'}\sa{\bar{x}'}(\successor(\bar{t}',\bar{t}) \mult h(\bar{t}',\bar{x}') \mult T_a(\bar{t}',\bar{x}') \mult s_{q}(\bar{t}') \mult out(\bar{t}')).
\end{align*}
Clearly, at each iteration of the LSFP operator, the tuple $\bar{t}$ represents the step the machine is currently in. From the construction of the formula, and since the machine is deterministic, it can be seen that in each function $g\in\{T_0,T_1,T_{\ttB},T_{\vdash},h,\hat{h}\}$, at the $\bar{a}$-th iteration of the LSFP operator, it holds that $g(\bar{a},\bar{b}) \leq 1$ for each $\bar{b}\in A^k$, that $g(\bar{a}+1,\bar{b}) = 0$ for each $\bar{b}\in A^k$. Also, at the $\bar{a}$-th iteration, $g(\bar{a}) \leq 1$ and $g(\bar{a}+1) = 0$ for each $g\in\{s_{q_1},\ldots,s_{q_{\ell}}\}$. From this, we have that at each iteration $\bar{a}$ of the operator, $out(\bar{a})$ is equal to either $2\cdot out(\bar{a}-1)$, $2\cdot out(\bar{a}-1) + 1$, or $out(\bar{a}-1)$, which represents precisely the value in the output tape at each step of $M$ running on input $\enc(\A)$. From this argument, it can be seen that $\sem{\alpha}(\A) = f(\enc(\A))$.

\medskip

To conclude the proof, we show that for each formula $\alpha$ in the previously defined extension of $\rqfo(\fo)$, there exists an equivalent formula confirming to the grammar of $\rqfo(\fo)$ defined in Section \ref{sec:beyond}. It suffices to consider a formula $\alpha$ of the form 
$$
\alpha(\bar{x}_1) = \clfp{f_1(\bar{x}_1): \alpha_1(\bar{x}_1,f_1,\ldots,f_n),\alpha_2(\bar{x}_2,f_1,\ldots,f_n),\ldots,\alpha_n(\bar{x}_n,f_1,\ldots,f_n)},
$$
and show an equivalent formula defined by a LSFP operator which uses one formula less in its definition.

We construct the equivalent formula as follows. We use a new function symbol $f$ with arity $\length{\bar{x}_1} + \length{\bar{x}_2}$. For every $i \in \{1,\ldots,n\}$, let $\alpha_i'$ be the formula obtained by performing the following replacements in $\alpha_i$:
\begin{align*}
f_1(\bar{y}_1) &\text{ is replaced by } \sa{\bar{y}_2}f(\bar{y}_1,\bar{y}_2)\mult[\first(\bar{y}_1)\mult\last(\bar{y}_2)  \add (\neg\first(\bar{y}_1))\mult\first(\bar{y}_2)], \\
f_2(\bar{y}_2) &\text{ is replaced by } \sa{\bar{y}_1}f(\bar{y}_1,\bar{y}_2)\mult[\first(\bar{y}_1)\mult\first(\bar{y}_2)  \add \last(\bar{y}_1)\mult(\neg\first(\bar{y}_2))].
\end{align*}
Moreover, let $\beta$ be a formula defined as:
\begin{align*}
\beta(\bar{x}_1,\bar{x}_2) = \,&\alpha_1'(\bar{x}_1)\mult(\first(\bar{x}_1)\mult\last(\bar{x}_2)  \add (\neg\first(\bar{x}_1))\mult\first(\bar{x}_2)) \add \\ &\alpha_2'(\bar{x}_2)\mult(\first(\bar{x}_1)\mult\first(\bar{x}_2)  \add \last(\bar{x}_1)\mult(\neg\first(\bar{x}_2))).
\end{align*}
It can be seen that all values of $f_1$, besides the first one, are stored in the first assignment of $\bar{x}_2$, while the first value of $f_1$ is stored in the last assignment of $\bar{x}_2$. Moreover, all values of $f_2$, besides the first one, are stored in the last assignment of $\bar{x}_1$, while the first value of $f_2$ is stored in the first assignment of $\bar{x}_1$. 
%This schema is depicted in Table \ref{table-clfp}. 
We use formula $\beta$ to define the following formula:
\begin{align*}
\alpha'(\bar{x}_1) = \,&\sa{\bar{x}_2}\clfp{f(\bar{x}_1,\bar{x}_2): \beta(\bar{x}_1,\bar{x}_2,f,f_3,\ldots,f_n),\\
&\alpha'_3(\bar{x}_3,f,f_3,\ldots,f_n),\ldots,\alpha'_n(\bar{x}_n,f,f_3,\ldots,f_n)}\mult(\first(\bar{x}_1)\mult\last(\bar{x}_2)  \add (\neg\first(\bar{x}_1))\mult\first(\bar{x}_2))
\end{align*}

It is not difficult to see that $\alpha'(\bar{x}_1)$ is equivalent to $\alpha(\bar{x}_1)$, which concludes the proof.

%
%We represent configurations with a tuple of fixed size. The formula $\varphi(\bar{x},\bar{y})$ describes a procedure that given a configuration generates a possible next configuration. The formula $\varphi_I(\bar{x})$ describes that $\bar{x}$ is the initial configuration of $M(w)$. The formula $\varphi_F(\bar{x})$ describes that $\bar{x}$ is an accepting (final) configuration of $M(w)$. The formula we construct is:
%$$
%\alpha = \sa{\bar{x}}\sa{\bar{y}}([\pth \varphi(\bar{x},\bar{y})]\mult \varphi_I(\bar{x})\mult\varphi_F(\bar{y})).
%$$
%
%To illustrate our idea, we will show a simplified example. Consider a machine $M$ that works in exactly $\log_2(n)$ space and only allows 0 or 1 in the working tape. Consider an input $\A$ of size 16 (that is, $A = \{0,\ldots,9,A,\ldots,F\}$). Let some configuration $s$ have 0011 in the working tape, the head in the input tape is in position 26, and the head in the input tape is in position 2 (we consider 0-indexed positions). Also, $Q = \{q_1,\ldots,q_5\}$ and the current state is $q_3$.
%
%As a first approach, we will use a 9-tuple $\bar{a} = (a_1,\ldots,a_9)$ to represent $s$. That is, $(a_1,a_2) = (1,A)$ represent the position of the head in the input tape (since 1A equal to 26 in base 16), $a_3 = 2$ represents the position of the head in the working tape, $a_4 = C$ (1100b in base 16) represents the content of the working tape, and $(a_5,\ldots,a_9) = (0,0,1,0,0)$ represents the current state. Then $\bar{a} = (1,A,2,C,0,0,1,0,0)$ will represent $s$.
%
%\newcommand\algx{\mathtt{x}}
%\newcommand\algy{\mathtt{y}}
%\newcommand\algz{\mathtt{z}}
%\newcommand\algu{\mathtt{u}}
%\newcommand\algv{\mathtt{v}}
%\newcommand\algi{\mathtt{i}}
%\newcommand\algj{\mathtt{j}}
%
%
%The problem that arises from this representation, is that to describe a transition in $M$ we need to read an arbitrary character in the working tape. (In the example, this translates to obtaining the $a_3$-th bit in $a_4$. Furthermore, to represent the next configuration, we need compute $a_4$ with the $a_3$-th bit flipped.) This is generally not possible to describe with an $\fo$ formula. To deal with this issue, consider the procedure defined in Algorithm \ref{switch1to0}. (In the example the procedure would receive $\algx = a_4$ and $\algi = a_3$.)
%
%\begin{algorithm}
%	\caption{If the $\algi$-th bit in $\algx$ is 1 replace it by 0 and return the result}
%	\label{switch1to0}
%	\begin{algorithmic}
%		\State $\algu \gets \algx,\; \algj \gets \algi$ \Comment{Get the $\algi$-th bit on $\algx$ and store it in $\algu$}
%		\While{$\algj > 0$}
%		\State $\algv \gets 0$
%		\While{$\algu > 1$}
%		\State $\algu \gets \algu-2,\; \algv \gets \algv+1$
%		\EndWhile
%		\State $\algu\gets \algv,\; \algj \gets \algj-1$
%		\EndWhile
%		\While{$\algu > 1$}
%		\State $\algu \gets \algu-2$
%		\EndWhile
%		\State $\textbf{assert } \algu = 1$ \Comment{If $\algu \neq 1$ simply stop}	
%		\State $\algy \gets 1$ \Comment{Compute $2^{\algi}$ and store it in $\algy$}
%		\While{$\algi > 0$}
%		\State $\algz \gets 0$
%		\While{$\algy > 0$}
%		\State $\algz \gets \algz+2,\; \algy \gets \algy-1$
%		\EndWhile
%		\State $\algi \gets \algi-1,\; \algy \gets \algz$
%		\EndWhile
%		\While{$\algy > 0$} \Comment{Subtract $\algy$ from $\algx$}
%		\State $\algx \gets \algx-1,\; y \gets \algy-1$
%		\EndWhile
%		\State \Return $\algx$.
%	\end{algorithmic}
%\end{algorithm}	
%Each of the instructions can be expressed with $\fo$, so our strategy is to use the $\pth$ operator to simulate the algorithm and then we can describe a transition using the processed value of $a_4$. This procedure simulates a transition that writes 1 in the cell where it read a 0. We call this a $1 \to 0$ transition. At the end of the proof we provide in detail three more procedures that simulate a $0\to 0$ transition, a $0\to 1$ transition, and a $1\to 1$ transition. The rest of the proof only addresses the case where we are simulating a $1\to 0$ transition, and the rest of the cases can be described analogously.
%
%We will now describe how to simulate both the procedure and the transition. A procedure tuple $\bar{p} = (a_1,\ldots,a_{3+c+\ell},b_1,b_2,c_1,c_2,c_3,d_1,\ldots,d_{5c+2})$ represents the current configuration of $M(w)$ in $a_1,\ldots,a_{2+c+\ell}$, the values that will be read and written in the working tape in $b_1,b_2$, the instruction pointer in $c_1,c_2,c_3$ and the values stored in memory in $d_1,\ldots,d_{10c+2}$. In detail:
%\begin{enumerate}
%	\item $a_1,a_2$ and $a_3$ represent the position of the head in the input tape and the working tape, respectively, $a_4,\ldots,a_{3+c}$ represent the content of the working tape and $a_{4+c},\ldots,a_{3+c+\ell}$ represent the current state in the current configuration that is being processed.
%	\item $b_1$ and $b_2$ are equal to the value that is being read in the working tape and the value that will be written in the working tape respectively. These values also indicate which algorithm is being simulated.
%	\item $c_1,c_2,c_2$ represent the instruction pointer in the procedure. Only 8 different instructions are needed in the simulation.
%	\item The variables $\algx,\algy,\algz,\algu,\algv$ need $c$ elements each to be represented and $\algi,\algj$ need only one. We map $(d_1\ldots,d_{c}) \to \algx$, $(d_{c+1}\ldots,d_{2c}) \to \algy$,
%	$(d_{2c+1}\ldots,d_{3c}) \to \algz$, $(d_{3c+1}\ldots,d_{4c}) \to \algu$,
%	$(d_{4c+1}\ldots,d_{5c}) \to \algv$, $d_{5c+1} \to \algi$ and $d_{5c+2}\to \algj$.
%\end{enumerate}
%For each transition $\delta \in \Delta \subseteq Q \times \{0,1\} \times \{0,1\} \times Q \times \{-1,=,+1\} \times \{0,1\} \times \{-1,=,+1\}$ we define a formula $\varphi_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v})$, where $\bar{x} = (x_1,\ldots,x_{3+c+\ell})$, $\bar{s} = (s_1,s_2)$, $\bar{w} = (w_1,w_2,w_3)$, $\bar{u} = (u_1,\ldots,u_{5c+2})$, $\bar{y} = (y_1,\ldots,y_{3+c+\ell})$, $\bar{t} = (t_1,t_2)$, $\bar{z} = (z_1,z_2,z_3)$ and $\bar{v} = (v_1,\ldots,v_{5c+2})$. The tuples $\bar{x}$ and $\bar{y}$ represent the current and next configuration of $M$ respectively, $\bar{s}$ and $\bar{t}$ indicate which algorithm is being simulated, $\bar{w}$ and $\bar{z}$ represent the current and next instruction of the algorithm, $\bar{u}$ and $\bar{v}$ represent the current and next values in memory. We will describe the formula part by part. Suppose $\delta = (q_i,a,1,q_j,op_1,0,op_2)$, so we have to simulate Algorithm \ref{switch1to0}.
%
%To significantly improve the readability of the construction, we define the following tuples:
%\begin{equation*}
%\begin{aligned}
%	\bar{x}_{\text{h-in}} &= (x_1,x_2), \\
%	x_{\text{h-w}} &= x_3, \\
%	\bar{x}_{\text{tape}} &= (x_4,\ldots,x_{3+c}),\\
%	\bar{x}_{\text{state}} &= (x_{4+c},\ldots,x_{3+c+\ell}),\\
%	\bar{u}_{\algx} &= (u_1,\ldots,u_c),\\
%	\bar{u}_{\algy} &= (u_{c+1},\ldots,u_{2c}),\\
%	\bar{u}_{\algz} &= (u_{2c+1},\ldots,u_{3c}),\\
%	\bar{u}_{\algu} &= (u_{3c+1},\ldots,u_{4c}),\\
%	\bar{u}_{\algv} &= (u_{4c+1},\ldots,u_{5c}),\\
%	u_{\algi} &= u_{5c+1},\\
%	u_{\algj} &= u_{5c+2},
%\end{aligned}
%\hspace{1em}
%\begin{aligned}
%	\bar{y}_{\text{h-in}} &= (y_1,y_2), \\
%	y_{\text{h-w}} &= y_3, \\
%	\bar{y}_{\text{tape}} &= (y_4,\ldots,y_{3+c}),\\
%	\bar{x}_{\text{state}} &= (x_{4+c},\ldots,x_{3+c+\ell}),\\
%	\bar{v}_{\algx} &= (v_1,\ldots,v_c),\\
%	\bar{v}_{\algy} &= (v_{c+1},\ldots,v_{2c}),\\
%	\bar{v}_{\algz} &= (v_{2c+1},\ldots,v_{3c}),\\
%	\bar{v}_{\algu} &= (v_{3c+1},\ldots,v_{4c}),\\
%	\bar{v}_{\algv} &= (v_{4c+1},\ldots,v_{5c}),\\
%	v_{\algi} &= v_{5c+1},\\
%	v_{\algj} &= v_{5c+2}.
%\end{aligned}
%\end{equation*}
%We also define some auxiliary formulas:
%\begin{align*}
%\gamma_{0}(\bar{x}) &= \neg\exists\bar{y}(\bar{y}<\bar{x}),\\
%\gamma_{1}(\bar{x}) &= \exists\bar{y}(\gamma_{0}(\bar{y})\wedge \bar{y} < \bar{x} \wedge \neg\exists\bar{z}(\bar{y}<\bar{z}\wedge\bar{z}<\bar{x}))\\
%\gamma_{+1}(\bar{x},\bar{y}) &= \bar{x} < \bar{y} \wedge \neg\exists \bar{z}(\bar{x}<\bar{z} \wedge \bar{z}<\bar{y}), \\
%\gamma_{-1}(\bar{x},\bar{y}) &= \gamma_{+1}(\bar{y},\bar{x}),\\
%\gamma_{=}(\bar{x},\bar{y}) &= \bar{x} = \bar{y} \\
%\gamma_{+2}(\bar{x},\bar{y}) &= \exists\bar{z}(\gamma_{+1}(\bar{x},\bar{z}) \wedge \gamma_{+1}(\bar{z},\bar{y})),\\
%\gamma_{-2}(\bar{x},\bar{y}) &= \gamma_{+2}(\bar{y},\bar{x}),\\
%\gamma_{i,j}(x,y) &= \gamma_i(x) \wedge \gamma_j(y),\text{ for $i,j \in\{0,1\}$}\\
%\varphi^b_k(x_1,x_2,x_3) &= \gamma_{a_1}(x_1) \wedge \gamma_{a_2}(x_2) \wedge \gamma_{a_3}(x_3),\text{ for each $k \leq 7$, where $a_1a_2a_3$ is the value of $k$ in binary}, \\
%\varphi^q_i(x_1,\ldots,x_{\ell}) &= \gamma_0(x_1) \wedge \mults \wedge \gamma_0(x_{i-1}) \wedge \gamma_1(x_i) \wedge \gamma_0(x_{i+1}) \wedge \mults \wedge \gamma_0(x_{\ell}), \text{ for each } q_i\in Q\\
%\varphi^E_0(x_1,x_2) &= \neg E(x_1,x_2),\\		\varphi^E_1(x_1,x_2) &= E(x_1,x_2),\\
%\end{align*}
%
%We start from instruction 0, which means that the procedure has not started yet and every value in the tuple is 0 except for the configuration values. It also initializes all the values in the tuple to 0 except for $\algx,\algu,\algi,\algj$.
%\begin{align*}
%\varphi^{0,1}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{0,0}(\bar{s})\wedge\varphi^b_0(\bar{w}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_1(\bar{z}) \wedge 
%\bar{v}_{\algx} = \bar{x}_{\text{tape}} \wedge 
%\gamma_0(\bar{v}_{\algy}) \wedge 
%\gamma_0(\bar{v}_{\algz}) \wedge 
%\bar{v}_{\algu} = \bar{x}_{\text{tape}} \wedge 
%\gamma_0(\bar{v}_{\algv}) \wedge 
%v_{\algi} = x_{\text{h-w}} \wedge v_{\algj} = x_{\text{h-w}}.
%\end{align*}
%Instruction 1 which checks whether the value of $\algj$ is more than 0 or not, and then proceeds to instruction 2 or 3 on each case.
%\begin{align*}
%\varphi^{1,2}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = 
%\,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_1(\bar{w}) \wedge \neg \gamma_0(u_{\algj}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_2(\bar{z}) \wedge \bar{u} = \bar{v}, \\
%\varphi^{1,3}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = 
%\,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_1(\bar{w}) \wedge \gamma_0(u_{\algj}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_3(\bar{z}) \wedge \bar{u} = \bar{v}.
%\end{align*}
%Instruction 2 checks the value of $\algu$. If it is $> 1$ then it subtracts 2 from $\algu$ and adds 1 to $\algv$, then repeats instruction 2. If it is equal to 0 or 1, then moves the value of $\algv$ to $\algu$, subtracts 1 from $\algj$ and goes back to instruction 1.
%\begin{align*}
%\varphi^{2,2}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = 
%\,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_2(\bar{w}) \wedge \neg \gamma_0(\bar{u}_{\algu}) \wedge \neg \gamma_1(\bar{u}_{\algu}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_2(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\bar{u}_{\algy} = \bar{v}_{\algy} \wedge
%\bar{u}_{\algz} = \bar{v}_{\algz} \wedge
%\gamma_{-2}(\bar{u}_{\algu},\bar{v}_{\algu}) \wedge
%\gamma_{+1}(\bar{u}_{\algv},\bar{v}_{\algv}) \wedge u_{\algi} = v_{\algi} \wedge u_{\algj} = v_{\algj},\\
%\varphi^{2,1}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_2(\bar{w}) \wedge ( \gamma_0(\bar{u}_{\algu}) \vee \gamma_1(\bar{u}_{\algu})) \wedge \\ 
%&\gamma_{1,0}(\bar{t}) \wedge \varphi^b_1(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\bar{u}_{\algy} = \bar{v}_{\algy} \wedge
%\bar{u}_{\algz} = \bar{v}_{\algz} \wedge
%\bar{u}_{\algv} = \bar{v}_{\algu} \wedge
%\gamma_0(\bar{v}_{\algv}) \wedge
%u_{\algi} = v_{\algi} \wedge \gamma_{-1}(u_{\algj},v_{\algj}).	
%\end{align*}
%Instruction 3 calculates the value of $\algu\mod 2$, that is, it repeats instruction 3 until the value of $\algu$ is equal to 0 or 1. On each iteration, it subtracts 2 from $\algu$. Moreover, if the value of $\algu$ at the end of the iterations is not 1 then there is no step defined.
%\begin{align*}
%\varphi^{3,3}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_3(\bar{w}) \wedge \neg \gamma_0(\bar{u}_{\algu}) \wedge \neg \gamma_1(\bar{u}_{\algu}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge 	\varphi^b_3(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\bar{u}_{\algy} = \bar{v}_{\algy} \wedge
%\bar{u}_{\algz} = \bar{v}_{\algz} \wedge
%\gamma_{-2}(\bar{u}_{\algu},\bar{v}_{\algu}) \wedge
%\bar{u}_{\algv} = \bar{v}_{\algv} \wedge
%u_{\algi} = v_{\algi} \wedge u_{\algj} = v_{\algj},\\
%\varphi^{3,3}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = 
%\,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_3(\bar{w}) \wedge \gamma_1(\bar{u}_{\algu}) \wedge\\ &\gamma_{1,0}(\bar{t}) \wedge 	\varphi^b_4(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\gamma_1(\bar{v}_{\algy}) \wedge
%\bar{u}_{\algz} = \bar{v}_{\algz} \wedge
%\bar{u}_{\algu} = \bar{v}_{\algu} \wedge
%\bar{u}_{\algv} = \bar{v}_{\algv} \wedge
%u_{\algi} = v_{\algi} \wedge u_{\algj} = v_{\algj}
%\end{align*}
%Instruction 4 checks the value of $\algi$. If it is not 0 then goes to instruction 5 and if is 0 then goes to instruction 6. Moreover it initializes the value of $\algz$ to 0 (which was 0 all along.)
%\begin{align*}
%\varphi^{4,5}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_4(\bar{w}) \wedge \neg \gamma_0(u_{\algi}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge 	\varphi^b_5(\bar{z}) \wedge \bar{u} = \bar{v}, \\
%\varphi^{4,6}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = &\gamma_{1,0}(\bar{s}) \wedge \varphi^b_4(\bar{w}) \wedge \gamma_0(u_{\algi}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge 	\varphi^b_6(\bar{z}) \wedge \bar{u} = \bar{v}.
%\end{align*}
%Instruction 5 checks the value of $\algy$. If it is more than 0 then it adds 2 to $\algz$ and subtracts 1 from $\algy$, then repeats instruction 2. If it is not, then copies the value of $\algz$ to $\algy$ and subtracts 1 from $\algi$ and returns to instruction 4.
%\begin{align*}
%\varphi^{5,5}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_5(\bar{w}) \wedge \neg \gamma_0(\bar{u}_{\algy}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_5(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\gamma_{-1}(\bar{u}_{\algy},\bar{v}_{\algy}) \wedge
%\gamma_{+2}(\bar{u}_{\algz},\bar{v}_{\algz})\, \wedge \bar{u}_{\algu} = \bar{v}_{\algu} \wedge
%\bar{u}_{\algv} = \bar{v}_{\algv} \wedge
%u_{\algi} = v_{\algi} \wedge u_{\algj} = v_{\algj},\\
%\varphi^{5,4}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_5(\bar{w}) \wedge \gamma_0(\bar{u}_{\algy}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_4(\bar{z}) \wedge
%\bar{u}_{\algx} = \bar{v}_{\algx} \wedge
%\bar{u}_{\algz} = \bar{v}_{\algy} \wedge
%\gamma_0(\bar{v}_{\algz}) \wedge
%\bar{u}_{\algu} = \bar{v}_{\algu} \wedge
%\bar{u}_{\algv} = \bar{v}_{\algv} \wedge
%\gamma_{-1}(u_{\algi},v_{\algi}) \wedge u_{\algj} = v_{\algj}
%\end{align*}
%Instruction 6 checks the value of $\algy$. If it is more than 0, then subtracts 1 from $\algx$ and $\algy$ and repeats instruction 6. If it is not, then goes to instruction 7.
%\begin{align*}
%\varphi^{6,6}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_6(\bar{w}) \wedge \neg \gamma_0(\bar{u}_{\algy}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_6(\bar{z}) \wedge
%\gamma_{-1}(\bar{u}_{\algx},\bar{v}_{\algx}) \wedge \gamma_{-1}(\bar{u}_{\algy},\bar{v}_{\algy}) \wedge \bar{u}_{\algu} = \bar{v}_{\algu} \wedge \bar{u}_{\algv} = \bar{v}_{\algv} \\
%\varphi^{6,7}_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \,&\gamma_{1,0}(\bar{s}) \wedge \varphi^b_6(\bar{w}) \wedge \gamma_0(\bar{u}_{\algy}) \wedge \\ &\gamma_{1,0}(\bar{t}) \wedge \varphi^b_7(\bar{z}) \wedge \bar{u} = \bar{v}.
%\end{align*}
%Instruction 7 stores the value of $\algx$ after the corresponding bit has been switched. Then we can define $\gamma_{\delta}$ which also simulates the actual transition. If $\algu$ equals 1, then copy what is stored in $\algx$ to $a_4,\ldots,a_{3+c}$, go from state $q_i$ to state $q_j$, and move the heads to their corresponding positions. Recall that $op_1,op_2\in\{+1,=,-1\}$
%\begin{align*}
%\gamma_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = 	[&\bar{x} = \bar{y} \wedge (\varphi^{0,1}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{1,2}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \varphi^{1,3}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{2,2}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \varphi^{2,1}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{3,3}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \varphi^{3,4}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{4,5}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \varphi^{4,6}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{5,5}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee  \varphi^{5,6}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \\ &\varphi^{6,6}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) \vee \varphi^{6,7}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}))] \, \vee \\
%[\varphi^E_a(\bar{x}_{\text{h-in}}) \wedge &\gamma_{1,0}(\bar{s}) \wedge \varphi^b_7(\bar{w}) \wedge \gamma_1(\bar{u}_{\algu}) \wedge \\ &\gamma_{0,0}(\bar{t}) \wedge \varphi^b_0(\bar{z}) \wedge \bar{u} = \bar{v} \wedge
%\gamma_{op_1}(\bar{x}_{\text{h-in}},\bar{y}_{\text{h-in}}) \wedge \gamma_{op_2}(x_{\text{h-w}},y_{\text{h-w}}) \wedge \bar{y}_{\text{tape}} = \bar{u}_{\algx} \wedge \varphi^q_i(\bar{x}_{\text{state}}) \wedge \varphi^q_j(\bar{y}_{\text{state}})].
%\end{align*}
%
%Note that we also need to specify that the program we are following is Algorithm \ref{switch1to0} so we store $1,0$ in $b_1,b_2$ all along the procedure. We describe the three other algorithms that compute the switches from $0\to 0$, $0\to 1$ and $1\to 1$ (Algorithms \ref{switch0to0}, \ref{switch0to1} and \ref{switch1to1}.)
%For the other three cases, where $\delta = (q_i,a,0,q_j,op_1,0,op_2)$, $\delta = (q_i,a,0,q_j,op_1,1,op_2)$ and $\delta = (q_i,a,1,q_j,op_1,1,op_2)$, $\gamma_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v})$ is defined analogously. Then, $\varphi(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v})$ is defined as:
%$$
%\varphi(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}) = \bigvee_{\delta \in \Delta} \gamma_{\delta}(\bar{x},\bar{s},\bar{w},\bar{u},\bar{y},\bar{t},\bar{z},\bar{v}).
%$$
%Lastly we define $\varphi_I$ and $\varphi_F$:
%\begin{align*}
%\varphi_I(\bar{x},\bar{s},\bar{w},\bar{u}) &= \gamma_0(\bar{x}_{\text{Head-1}}) \wedge \gamma_0(x_{\text{Head-2}}) \wedge \gamma_0(\bar{x}_{\text{Tape}}) \wedge \varphi^{q}_1(\bar{x}_{\text{State}})\wedge \gamma_{0,0}(\bar{s})\wedge \varphi^b_0(\bar{w}) \wedge\gamma_0(\bar{u}). \\
%\varphi_F(\bar{x},\bar{s},\bar{w},\bar{u}) &= \varphi^q_{\ell}(\bar{x}_{\text{State}}) \wedge \gamma_{0,0}(\bar{s}) \wedge \varphi^b_0(\bar{w}) \wedge\gamma_0(\bar{u}),
%\end{align*}
%and then $\sem{\alpha}(\A) = \sem{\sa{\bar{x}}\sa{\bar{y}}([\pth \varphi(\bar{x},\bar{y})]\mult \varphi_I(\bar{x})\mult\varphi_F(\bar{y}))}(\A) = \acc_M(\A)$.
%
%\begin{algorithm}
%	\caption{If the $i$-th bit in $x$ is 0 return $x$} \label{switch0to0}
%	\begin{algorithmic}
%		\State $u \gets x,\; j \gets i$ \Comment{Get the $i$-th bit on $x$ and store it in $u$}
%		\While{$j > 0$}
%		\State $v \gets 0$
%		\While{$u > 1$}
%		\State $u \gets u-2,\; v \gets v+1$
%		\EndWhile
%		\State $u\gets v,\; j \gets j-1$
%		\EndWhile
%		\While{$u > 1$}
%		\State $u \gets u-2$
%		\EndWhile
%		\State $\textbf{assert } u = 0$ \Comment{If $u \neq 0$ simply stop}	
%		\State \Return $x$.
%	\end{algorithmic}
%\end{algorithm}
%
%\begin{algorithm}
%	\caption{If the $i$-th bit in $x$ is 0 replace it by 1 and return the result}
%	\label{switch0to1}
%	\begin{algorithmic}
%		\State $u \gets x,\; j \gets i$ \Comment{Get the $i$-th bit on $x$ and store it in $u$}
%		\While{$j > 0$}
%		\State $v \gets 0$
%		\While{$u > 1$}
%		\State $u \gets u-2,\; v \gets v+1$
%		\EndWhile
%		\State $u\gets v,\; j \gets j-1$
%		\EndWhile
%		\While{$u > 1$}
%		\State $u \gets u-2$
%		\EndWhile
%		\State $\textbf{assert } u = 0$ \Comment{If $u \neq 0$ simply stop}	
%		\State $y \gets 1$ \Comment{Compute $2^i$ and store it in $y$}
%		\While{$i > 0$}
%		\State $z \gets 0$
%		\While{$y > 0$}
%		\State $z \gets z+2,\; y \gets y-1$
%		\EndWhile
%		\State $i \gets i-1,\; y \gets z$
%		\EndWhile
%		\While{$y > 0$} \Comment{Add $y$ to $x$}
%		\State $x \gets x+1,\; y \gets y-1$
%		\EndWhile
%		\State \Return $x$.
%	\end{algorithmic}
%\end{algorithm}	
%
%\begin{algorithm}
%	\caption{If the $i$-th bit in $x$ is 1 return $x$}
%	\label{switch1to1}
%	\begin{algorithmic}
%		\State $u \gets x,\; j \gets i$ \Comment{Get the $i$-th bit on $x$ and store it in $u$}
%		\While{$j > 0$}
%		\State $v \gets 0$
%		\While{$u > 1$}
%		\State $u \gets u-2,\; v \gets v+1$
%		\EndWhile
%		\State $u\gets v,\; j \gets j-1$
%		\EndWhile
%		\While{$u > 1$}
%		\State $u \gets u-2$
%		\EndWhile
%		\State $\textbf{assert } u = 1$ \Comment{If $u \neq 0$ simply stop}	
%		\State \Return $x$.
%	\end{algorithmic}
%\end{algorithm}
%
%
%%
%%
%%
%%
%%
%%
%%\medskip
%%
%%\subsection*{Proof of Theorem \ref{tqso-fo-fpsace}}
%%
%%We separate the proof in two parts. Let $\R$ be a relational signature. First we prove that for every formula $\alpha$ in $\tqso$ over $\R$ there exists a function $f\in\shpspace$ such that $\sem{\alpha}(\A) = f(\enc(\A))$ for every $\A\in\ostr[\R]$. Then we prove that for every function $f\in \fpspace$ over $\R$ there exists a $\tqso(\fo)$ formula $\alpha$ such that $f(\enc(\A)) = \sem{\alpha}(\A)$ for every $\A\in\ostr[\R]$. By the inclusion of $\tqso(\fo)\subseteq\tqso$ and the equality $\shpspace = \fpspace$, this proves that both $\tqso$ and $\tqso(\fo)$ capture $\fpspace$ over ordered structures.
%%
%%\vspace{1em}
%%For the first part, let $\alpha$ be a formula in $\tqso$ over $\R$. 
%%We will construct a nondeterministic polynomial-space algorithm $M_{\alpha}$ that on input $(\enc(\A),\enc(v),\enc(V))$, accepts in $\sem{\alpha}(\A,v,V)$ paths, for each $(\A,v,V)\in\ostr[\R]^*$. Let $A = \{1,\ldots,n\}$  be the domain of $\A$. 
%%First-order assignments are encoded as a simple mapping from every first-order variable mentioned in $\alpha$ to an element in $A$. 
%%Second order assignments are encoded in polynomial space as a mapping from every second-order variable $X$ to a subset of $A^{\arity(X)}$. We now begin the construction of the algorithm. 
%%If $\alpha = \varphi$, a $\so$ formula, we check if $(\A,v,V)\models\varphi$ in deterministic polynomial space, and accept if and only if it holds. 
%%If $\alpha = s$, we generate $s$ branches and accept in all of them. 
%%If $\alpha = (\alpha_1 + \alpha_2)$, we simulate $M_{\alpha_1}$ and $M_{\alpha_2}$, both on input $(A,v,V)$, on separate branches. 
%%If $\alpha = (\alpha_1\mult\alpha_2)$, we simulate $\alpha_1$ on input $(A,v,V)$ and if it accepts, instead of doing so, we simulate $\alpha_2$ on input $(A,v,V)$. 
%%If $\alpha = \sa{x}\beta$, for each $a\in A$ we generate a different branch where we simulate $M_{\beta}$ on input $(A,v[a/x],V)$.
%%If $\alpha = \pa{x}\beta$, we simulate $M_{\beta}$ on input $(A,v[1/x],V)$, and on each accepting branch, instead of accepting we simulate $M_{\beta}$ on input $(A,v[2/x],V)$, and so on. 
%%If $\alpha = \sa{X}\beta$, for each $B\subseteq A^{\arity(X)}$ we generate a different branch where we simulate $M_{\beta}$ on input $(A,v,V[B/X])$.
%%If $\alpha = \pa{X}\beta$, we simulate $M_{\beta}$ on input $(\A,v,V[B/X])$ consecutively for each $B\subseteq A^{\arity(X)}$. 
%%If $\alpha = [\pth \varphi(\bar{x},\bar{X},\bar{y},\bar{Y})]$ where $\varphi$ is an $\so$ formula, we simulate the procedure that counts the number of paths for a graph of a given size. This procedure starts with $(\bar{b},\bar{B}) = (v(\bar{x}),V(\bar{X}))$, then on each iteration, nondeterministically chooses an assignment $(\bar{a},\bar{B})$ for $(\bar{x},\bar{X})$, and checks in polynomial space if $(\A,v,V)\models\varphi(\bar{a}',\bar{B}',\bar{a},\bar{B})$, where $(\bar{a}',\bar{B}')$ is the previously chosen value. If it holds, we continue, and otherwise we reject. If at any point we obtain that $(\bar{b}, \bar{B}) = (v(\bar{y}),V(\bar{Y}))$ we generate a new accepting branch, and we continue with the procedure.
%%We compute $n^{\length{\bar{x}}}\mult \prod_{X\in\bar{X}} 2^{A^{\arity(X)}}$ iterations of the procedure, which generates exactly $\sem{[\pth \varphi(\bar{x},\bar{X},\bar{y},\bar{Y})]}(\A,v,V)$ accepting branches. 
%%This ends the construction of the algorithm. 
%%Consider $f$ as the $\shpspace$ function associated to this procedure and we have that for each finite $\R$-structure $\A$: $f(\enc(\A)) = \sem{\alpha}(\A)$.
%%
%%\vspace{1em}
%%For the second part let $f\in\fpspace$ over some relational signature $\R$. We use our proof for theorem \ref{theo:capture-fpspace} and recall the formula
%%$$
%%\alpha := \sa{X}(\Phi(X)\mult\gamma(X))
%%$$
%%that satisfies $\sem{\alpha}(\A) = f(\enc(\A))$ for each $\R$-structure $\A$, where $\Phi(X)$ is a $\pfp$ formula that models a $\pspace$ language over the encoding of structures in $\ostr[\R\cup\{X\}]$. The typical reduction  for this \cite{G07} uses a first-order over $\R\cup\{X,R\}$ formula $\psi(R,\bar{x})$ and describes $\Phi = \exists\bar{y}\,[\mathbf{pfp}\,R(\bar{x}):\psi(R,\bar{x})](\bar{y})$ (note that $X$ might be mentioned in $\psi$). We will provide an equivalent formula $\zeta(X)$ in $\tqso(\fo)$:
%%$$
%%\zeta(X) := \sa{R}\sa{S}\sa{Y}[\pth\varphi(X,R,Y,S)]\mult\forall\bar{x}(X(\bar{x})\leftrightarrow,v Y(\bar{x}))\mult\forall\bar{y}\neg R(\bar{y})\mult\forall\bar{y}(S(\bar{y})\leftrightarrow,v\psi(X,S,\bar{y}))\mult\exists\bar{y}S(\bar{y}),
%%$$
%%where $\varphi$ is defined as:
%%$$
%%\varphi(X,R,Y,S) := \forall\bar{x}(X(\bar{x})\leftrightarrow,v Y(\bar{x}))\wedge\forall\bar{y}(S(\bar{y})\leftrightarrow,v\psi(X,R,\bar{y}))\wedge\neg\forall\bar{y}(R(\bar{y})\leftrightarrow,v\psi(X,R,\bar{y})).
%%$$
%%The formula $\neg\forall\bar{y}(R(\bar{y})\leftrightarrow,v\psi(R,\bar{y}))$ prevents $R$ from already being a fixed point. This way, the operator finds a fixed point $S$ and then stops iterating. It can be checked that in the graph described for this operator, each node has out-degree and in-degree at most 1. And so, $\sem{\zeta(X)}(\A,v,V)$ takes the value 0 or 1 for each $(\A,v,V)\in\ostr[\R]^*$. Then the formula
%%$$
%%\alpha := \sa{X}(\zeta(X)\mult\gamma(X))
%%$$
%%is in $\tqso(\fo)$ and satisfies $\sem{\alpha}(\A) = f(\enc(\A))$ for each $\A\in\ostr[\R]$.
%%
%%\subsection*{Proof of Theorem \ref{tqsos-shp}}
%%
%%
%%\vspace{1em}
%%Let $\R$ be a signature. We will first prove the first condition in Definition \ref{def:cap}. Let $\alpha$ be a formula in $\tqsos(\fo)$ over $\R$. 
%%We will construct a nondeterministic polynomial-space algorithm $M_{\alpha}$ that on input $(\enc(\A),\enc(v),\enc(V))$, accepts in $\sem{\alpha}(\A,v,V)$ paths, for each $(\A,v,V)\in\ostr[\R]^*$. Let $A = \{1,\ldots,n\}$  be the domain of $\A$. 
%%First-order assignments are encoded as a simple mapping from every first-order variable mentioned in $\alpha$ to an element in $A$. 
%%Second order assignments are encoded in polynomial space as a mapping from every second-order variable $X$ to a subset of $A^{\arity(X)}$. We now begin the construction of the algorithm. 
%%If $\alpha = \varphi$, a $\so$ formula, we check if $(\A,v,V)\models\varphi$ in deterministic polynomial space, and accept if and only if it holds. 
%%If $\alpha = s$, we generate $s$ branches and accept in all of them. 
%%If $\alpha = (\alpha_1 + \alpha_2)$, we simulate $M_{\alpha_1}$ and $M_{\alpha_2}$, both on input $(A,v,V)$, on separate branches. 
%%If $\alpha = (\alpha_1\mult\alpha_2)$, we simulate $\alpha_1$ on input $(A,v,V)$ and if it accepts, instead of doing so, we simulate $\alpha_2$ on input $(A,v,V)$. 
%%If $\alpha = \sa{x}\beta$, for each $a\in A$ we generate a different branch where we simulate $M_{\beta}$ on input $(A,v[a/x],V)$.
%%If $\alpha = \pa{x}\beta$, we simulate $M_{\beta}$ on input $(A,v[1/x],V)$, and on each accepting branch, instead of accepting we simulate $M_{\beta}$ on input $(A,v[2/x],V)$, and so on. 
%%If $\alpha = \sa{X}\beta$, for each $B\subseteq A^{\arity(X)}$ we generate a different branch where we simulate $M_{\beta}$ on input $(A,v,V[B/X])$.
%%If $\alpha = [\pth \varphi(\bar{x},\bar{X},\bar{y},\bar{Y})]$ where $\varphi$ is an $\so$ formula, we simulate the procedure that counts the number of paths for a graph of a given size. This procedure starts with $(\bar{b},\bar{B}) = (v(\bar{x}),V(\bar{X}))$, then on each iteration, nondeterministically chooses an assignment $(\bar{a},\bar{B})$ for $(\bar{x},\bar{X})$, and checks in polynomial space if $(\A,v,V)\models\varphi(\bar{a}',\bar{B}',\bar{a},\bar{B})$, where $(\bar{a}',\bar{B}')$ is the previously chosen value. If it holds, we continue, and otherwise we reject. If at any point we obtain that $(\bar{b}, \bar{B}) = (v(\bar{y}),V(\bar{Y}))$ we generate a new accepting branch, and we continue with the procedure.
%%We compute $n^{\length{\bar{x}}}\mult \prod_{X\in\bar{X}} 2^{A^{\arity(X)}}$ iterations of the procedure, which generates exactly $\sem{[\pth \varphi(\bar{x},\bar{X},\bar{y},\bar{Y})]}(\A,v,V)$ accepting branches. 
%%This ends the construction of the algorithm. 
%%Consider $f$ as the $\shpspace$ function associated to this procedure and we have that for each finite $\R$-structure $\A$: $f(\enc(\A)) = \sem{\alpha}(\A)$.
%%
%%\vspace{1em}
%%For the second part let $f\in\shp$ over some relational signature $\R$.
%%

\subsection*{Proof of Theorem \ref{tqfo-shl}}
$\boldsymbol{\tqfo(\fo)}$ {\bf can be computed in} $\boldsymbol{\shl.}$
Let $\R$ be some relational signature. Let $\alpha$ be a formula in $\tqfo(\fo)$. We will construct a nondeterministic logspace algorithm $M_{\alpha}$ that on input $\enc(\A)$, where a first-order assignment $v$ is being stored in memory, accepts in $\sem{\alpha}(\A,v)$ paths. Suppose the domain of $\A$ is $A = \{1,\ldots,n\}$. The algorithm needs $c\mult\log_2(n)$ bits of memory to store $v$, where $c$ is the total number of first-order variables in $\alpha$. If $\alpha = \varphi$, we check if $(\A,v)\models\varphi$ in deterministic logarithmic space, and accept if and only if it does. If $\alpha = s$, we generate $s$ branches and accept in all of them. If $\alpha = (\alpha_1 + \alpha_2)$, we simulate $M_{\alpha_1}$ and $M_{\alpha_2}$ on separate branches. If $\alpha = (\alpha_1\mult\alpha_2)$, we simulate $\alpha_1$ and if it accepts, instead of doing so, we simulate $\alpha_2$. If $\alpha = \sa{x}\beta$, for each $a\in A$ we generate a different branch where we simulate $M_{\beta}$ while storing $v[a/x]$. If $\alpha = \pa{x}\beta$, we simulate $M_{\beta}$ while storing $v[1/n]$, and on each accepting branch, instead of accepting we replace the assignment on $x$ to 2, to simulate $M_{\beta}$ while storing $v[2/x]$, and so on. If $\alpha = [\pth \varphi(\bar{x},\bar{y})]$ where $\varphi$ is an $\fo$ formula, we simulate the $\shl$ procedure that counts the number of paths for a graph of a given size. This procedure starts by setting $\bar{a} = v(\bar{x})$. On each iteration, nondeterministically chooses an assignment $\bar{a}$ for $\bar{x}$, continues if $(\A,v)\models\varphi(\bar{a}',\bar{a})$ where $\bar{a}'$ is the previously chosen value for $\bar{a}$, and rejects otherwise. If at any point we obtain that $\bar{a} = v(\bar{y})$, we generate an accepting branch, and continue simulating the procedure in the current branch. We simulate $n^{\length{\bar{x}}}$ iterations of the procedure, and this generates exactly $\sem{[\pth \varphi(\bar{x},\bar{y})]}(\A,v)$ accepting branches. This ends the construction of the algorithm. Consider $f$ as the $\shl$ function associated to this procedure and we have that for each finite $\R$-structure $\A$: $f(\enc(\A)) = \sem{\alpha}(\A)$.

\vspace{1em}
$\boldsymbol{\shl}$ {\bf can be modelled in }$\boldsymbol{\tqfo(\fo).}$ Let $f$ be a function in $\shl$ and let $M$ be a nondeterministic logspace machine such that $\acc_{M}(\enc(\A)) = f(\enc(\A))$. We assume that $M$ has only one accepting state and upon accepting it immediately stops. Moreover, we assume that there exists only one accepting configuration altogether. We make use of transitive closure logic ($\tc$) to simplify our proof. We have that $\tc$ captures $\nlog$\cite{I83}, so there exists a formula such that $\A\models\varphi$ if and only if $M$ accepts $\enc(\A)$. This formula can be expressed as:
$$
\varphi = \exists\bar{u}\exists\bar{z}(\first(\bar{u})\wedge \psi_{\bf acc}(\bar{z})\wedge[{\bf tc}_{\bar{x},\bar{y}}\,\psi_{\bf next}(\bar{x},\bar{y})](\bar{u},\bar{z})),
$$
where $\psi_{\bf acc}(\bar{z})$ is an $\fo$ formula that expresses that $\bar{z}$ is an accepting configuration, and $\psi_{\bf next}(\bar{x},\bar{y})$ is an $\fo$ formula that expresses that $\bar{y}$ is a configuration reachable from $\bar{x}$. This construction was provided in \cite{G07}. Here, there is a 1-1 correspondence between configurations of $M$ and assignments to $\bar{z}$. As a consequence, given a structure $\A$, and a first-order assignment $v$ to $\A$ where $v(\bar{x})$ is the starting configuration and $v(\bar{y})$ is the sole accepting configuration, the value of $\sem{[\pth\psi_{\bf next}(\bar{x},\bar{y})]}(\A,v)$ is equal to $\acc_M(\enc(\A))$.

Lastly, we define the $\tqfo(\fo)$ formula
$$
\alpha = \sa{\bar{u}}\sa{\bar{z}}(\first(\bar{u})\mult\psi_{\bf acc}(\bar{z})\mult[\pth \psi_{\bf next}(\bar{u},\bar{z})]),
$$
which satisfies $\sem{\alpha}(\A) = f(\enc(\A))$ for each structure $\A$. This concludes the proof.


%\vspace{1em}
%$\boldsymbol{\tqfo(\dtc) = \tqfo(\fo).}$ The to direction is trivial, so we only prove the from direction. We will construct a function $\tau$ that receives a formula $\alpha$ in $\rqfo(\dtc)$ and outputs an equivalent formula $\tau(\alpha)$ in $\rqfo(\fo)$.
%
%Suppose $\alpha = \varphi(\bar{w})$ where $\varphi$ is a formula in $\dtc$ logic. Using the fact that $\dtc$ logic captures $\nlog$ \cite{G07}, we consider a nondeterministic logspace machine $M$ that accepts $\enc(\A)\cdot \enc(v(\bar{w}))$ if and only if $(\A,v)\models\varphi(\bar{w})$, for each structure $\A$ and first-order assignment $v$ for $\A$. We assume that the machine has only one final state and after reaching it immediately stops. Using the same result, we construct a $\dtc$ formula that expresses the condition that $M$ accepts $\enc(\A)\cdot\enc(v(\bar{w}))$. While the result only considers an input of a sole structure $\enc(\A)$, it can be easily extended by considering the appended assignment $v(\bar{w})$ as a tuple of constants added to the structure. We use the construction provided in \cite{G07}, which uses a pair of $\fo$ formulas which we call $\psi_{\bf acc}(\bar{z})$ and $\psi_{\bf next}(\bar{x},\bar{y})$, and models the condition with the formula:
%$$
%\varphi'(\bar{w}) = \exists\bar{z}\exists\bar{u}(\psi_{\bf acc}(\bar{w},\bar{z})\wedge\first(\bar{u})\wedge [{\bf dtc}_{\bar{x},\bar{y}}\,\psi_{\bf next}(\bar{x},\bar{y},\bar{w})](\bar{u},\bar{z}))
%$$
%Note that we have to include $\bar{w}$ as free variables in $\psi_{\bf acc}$ and $\psi_{\bf next}$. The construction models the machine by encoding configurations as tuples. We define $\tau(\varphi)$ as:
%$$
%\sa{\bar{z}}\sa{\bar{u}}(\psi_{\bf acc}(\bar{w},\bar{z})\mult\first(\bar{u})\mult[{\bf path}_{\bar{x},\bar{y}} \psi_{\bf next}(\bar{w},\bar{x},\bar{y})](\bar{u},\bar{z})).
%$$
%Note that from our suppositions on the machine, we have that if it accepts, there exists only one accepting configuration, and therefore at most one assignment for $\bar{z}$ will be counted by its first-order sum. Furthermore, the ${\bf path}$ operator computes the transitive closure of the formula $\psi_{\bf next}$ which simulates a {\em deterministic} machine, and so the operator always takes value 0 or 1. From this we deduce that $\tau(\varphi)$ is equivalent to $\varphi$. This finishes the case where $\alpha = \varphi$ in $\dtc$.
%
%For the general case, let $\alpha$ be a $\rqfo(\dtc)$ formula. We simply replace each $\dtc$ formula $\varphi$ in $\alpha$ by $\tau(\varphi)$ and we define the resulting formula as $\tau(\alpha)$ which clearly is equivalent to $\alpha$. This concludes the proof.
